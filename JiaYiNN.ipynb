{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of Iris Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Iris Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "#print(iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we will process the Iris Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = iris.data\n",
    "#print(features)\n",
    "target = iris.target\n",
    "#print(len(target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting to 20% test 80% train\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, target, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we will standardize the values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiaing the number of classes and features for the training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_count = x_train.shape[1]\n",
    "print(features_count)\n",
    "classes = len(np.unique(target))\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting them into Pytorch Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tensor = torch.tensor(x_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "x_test_tensor = torch.tensor(x_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building up the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "dnn_model = Sequential(Linear(features_count,10), nn.ReLU(),\n",
    "                       Linear(10,20), nn.ReLU(),\n",
    "                       Linear(20,15), nn.ReLU(),\n",
    "                       Linear(15, classes)).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_acc(model, X_data, y_data, device):\n",
    "    model.eval() #Evaluation Model\n",
    "    with torch.no_grad(): #Disable gradient calculation to save computation energy \n",
    "        X_data, y_data = X_data.to(device), y_data.to(device)\n",
    "        #use the model to predict the results\n",
    "        outputs = model(X_data.type(torch.float32))  \n",
    "        #choose the highest probability for each row so it belongs to the certain class\n",
    "        predicted = torch.argmax(outputs.data, 1)\n",
    "        corrects = (predicted == y_data.type(torch.long)).sum().item()\n",
    "        totals = y_data.size(0)\n",
    "        acc = float(corrects) / totals\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to create model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "\tdnn_model = Sequential(Linear(features_count,10), nn.ReLU(),\n",
    "                         Linear(10,20), nn.ReLU(),\n",
    "                         Linear(20,15), nn.ReLU(),\n",
    "                         Linear(15, classes))\n",
    "\treturn dnn_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model=None, X_train=None, y_train=None, loss_fn=None, optimizer=torch.optim.Adam,\n",
    "        learning_rate=0.001, num_epochs=100, verbose=True, seed=1234, device=None):\n",
    "    torch.manual_seed(seed)\n",
    "    optim = optimizer(model.parameters(), lr=learning_rate)\n",
    "    history = dict()\n",
    "    history['train_loss'] = []\n",
    "    history['train_acc'] = []\n",
    "\n",
    "    # Move data to device\n",
    "    X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        #allow the model to go in training mode\n",
    "        model.train()\n",
    "        \n",
    "        #foward propaogation\n",
    "        outputs = model(X_train.type(torch.float32))\n",
    "        loss = loss_fn(outputs, y_train.type(torch.long))\n",
    "        \n",
    "        #make sure the gradient computed is zero so it doesnt accumulate from previous iteration\n",
    "        optim.zero_grad()\n",
    "        #conpute the gradient lost\n",
    "        loss.backward()\n",
    "        #update the weights\n",
    "        optim.step()\n",
    "\n",
    "        #evaluate the accuracy for this current epoch\n",
    "        model.eval()  # Set the model to evaluation mode\n",
    "        train_loss = compute_loss(model, loss_fn, X_train, y_train, device)\n",
    "        train_acc = compute_acc(model, X_train, y_train, device)\n",
    "\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "            print(f\"train loss= {train_loss:.4f} - train acc= {train_acc*100:.2f}%\")\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training model and choosing the optimiser "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "optim_dict = {\"Adam\":optim.Adam, \"Adadelta\":optim.Adadelta, \"Adagrad\":optim.Adagrad,\n",
    "              \"Adamax\":optim.Adamax, \"AdamW\": optim.AdamW, \"ASGD\":optim.ASGD,\n",
    "              \"NAdam\":optim.NAdam, \"RMSprop\":optim.RMSprop, \"RAdam\":optim.RAdam,\n",
    "              \"Rprop\": optim.Rprop, \"SGD\":optim.SGD}\n",
    "\n",
    "dnn_model = create_model().to(device)\n",
    "history = fit(dnn_model, X_train = x_train_tensor, y_train=y_train_tensor, loss_fn = nn.CrossEntropyLoss(),\n",
    "    optimizer = optim_dict[\"SGD\"], learning_rate = 0.1, num_epochs = 50, verbose= True, seed=123, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = compute_acc(dnn_model, x_test_tensor, y_test_tensor, device)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
